{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('/home/ubuntu/hi-env/image-processing-labs/linear-regression,10-1/data.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLoss(x,y,a):\n",
    "    loss=0\n",
    "    for i in range(0,4):\n",
    "        loss+=(x[i]*a-y[i])**2\n",
    "    return loss/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeGrad(x,y,a):\n",
    "    grad=0\n",
    "    grad+=(2*x*x*a-2*x*y)/4\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 348056.25\n",
      "0 a: 11\n",
      "1 loss: 66904.0129534005\n",
      "1 a: 5.4668492109375\n",
      "2 loss: 12746.000296460632\n",
      "2 a: 3.0291574260973793\n",
      "3 loss: 2415.7585403286275\n",
      "3 a: 1.9552049052979514\n",
      "4 loss: 490.68684323364045\n",
      "4 a: 1.4820630486841588\n",
      "5 loss: 152.27255259343926\n",
      "5 a: 1.2736150846034864\n",
      "6 loss: 102.10970137597758\n",
      "6 a: 1.1817809906166499\n",
      "7 loss: 99.21151087554931\n",
      "7 a: 1.1413224480946456\n",
      "8 loss: 101.66160322029093\n",
      "8 a: 1.1234979823440556\n",
      "9 loss: 103.46439306737312\n",
      "9 a: 1.115645213571647\n",
      "10 loss: 104.39903512884148\n",
      "10 a: 1.1121855880066636\n",
      "11 loss: 104.83805355256398\n",
      "11 a: 1.1106614110702508\n",
      "12 loss: 105.03675738504894\n",
      "12 a: 1.1099899177858312\n",
      "13 loss: 105.12532522070873\n",
      "13 a: 1.1096940838703269\n",
      "14 loss: 105.16454403902986\n",
      "14 a: 1.109563750913031\n",
      "15 loss: 105.18186100606793\n",
      "15 a: 1.1095063312634668\n",
      "16 loss: 105.18949769731063\n",
      "16 a: 1.1094810343913288\n",
      "17 loss: 105.19286358450427\n",
      "17 a: 1.1094698895699162\n",
      "18 loss: 105.19434674674517\n",
      "18 a: 1.1094649795935507\n",
      "19 loss: 105.1950002254339\n",
      "19 a: 1.109462816448264\n",
      "20 loss: 105.19528813347043\n",
      "20 a: 1.1094618634502895\n",
      "21 loss: 105.19541497666052\n",
      "21 a: 1.109461443596318\n",
      "22 loss: 105.19547085925517\n",
      "22 a: 1.1094612586249308\n",
      "23 loss: 105.19549547903839\n",
      "23 a: 1.1094611771337066\n",
      "24 loss: 105.19550632557582\n",
      "24 a: 1.1094611412318318\n",
      "25 loss: 105.19551110414272\n",
      "25 a: 1.1094611254148572\n",
      "26 loss: 105.19551320939466\n",
      "26 a: 1.1094611184465113\n",
      "27 loss: 105.19551413688723\n",
      "27 a: 1.1094611153765281\n",
      "28 loss: 105.19551454550457\n",
      "28 a: 1.1094611140240125\n",
      "29 loss: 105.19551472552536\n",
      "29 a: 1.1094611134281467\n",
      "30 loss: 105.19551480483568\n",
      "30 a: 1.1094611131656311\n",
      "31 loss: 105.19551483977673\n",
      "31 a: 1.109461113049977\n",
      "32 loss: 105.1955148551704\n",
      "32 a: 1.1094611129990242\n",
      "33 loss: 105.19551486195223\n",
      "33 a: 1.1094611129765766\n",
      "34 loss: 105.19551486494004\n",
      "34 a: 1.109461112966687\n",
      "35 loss: 105.1955148662564\n",
      "35 a: 1.1094611129623297\n",
      "36 loss: 105.19551486683638\n",
      "36 a: 1.1094611129604102\n",
      "37 loss: 105.1955148670918\n",
      "37 a: 1.1094611129595646\n",
      "38 loss: 105.19551486720428\n",
      "38 a: 1.109461112959192\n",
      "39 loss: 105.19551486725396\n",
      "39 a: 1.109461112959028\n",
      "40 loss: 105.19551486727582\n",
      "40 a: 1.1094611129589556\n",
      "41 loss: 105.19551486728538\n",
      "41 a: 1.1094611129589238\n",
      "42 loss: 105.19551486728956\n",
      "42 a: 1.1094611129589098\n",
      "43 loss: 105.19551486729151\n",
      "43 a: 1.1094611129589036\n",
      "44 loss: 105.19551486729232\n",
      "44 a: 1.1094611129589007\n",
      "45 loss: 105.19551486729267\n",
      "45 a: 1.1094611129588996\n",
      "46 loss: 105.19551486729289\n",
      "46 a: 1.109461112958899\n",
      "47 loss: 105.19551486729299\n",
      "47 a: 1.1094611129588987\n",
      "48 loss: 105.19551486729299\n",
      "48 a: 1.1094611129588987\n",
      "49 loss: 105.19551486729299\n",
      "49 a: 1.1094611129588987\n",
      "50 loss: 105.19551486729299\n",
      "50 a: 1.1094611129588987\n",
      "51 loss: 105.19551486729299\n",
      "51 a: 1.1094611129588987\n",
      "52 loss: 105.19551486729299\n",
      "52 a: 1.1094611129588987\n",
      "53 loss: 105.19551486729299\n",
      "53 a: 1.1094611129588987\n",
      "54 loss: 105.19551486729299\n",
      "54 a: 1.1094611129588987\n",
      "55 loss: 105.19551486729299\n",
      "55 a: 1.1094611129588987\n",
      "56 loss: 105.19551486729299\n",
      "56 a: 1.1094611129588987\n",
      "57 loss: 105.19551486729299\n",
      "57 a: 1.1094611129588987\n",
      "58 loss: 105.19551486729299\n",
      "58 a: 1.1094611129588987\n",
      "59 loss: 105.19551486729299\n",
      "59 a: 1.1094611129588987\n",
      "60 loss: 105.19551486729299\n",
      "60 a: 1.1094611129588987\n",
      "61 loss: 105.19551486729299\n",
      "61 a: 1.1094611129588987\n",
      "62 loss: 105.19551486729299\n",
      "62 a: 1.1094611129588987\n",
      "63 loss: 105.19551486729299\n",
      "63 a: 1.1094611129588987\n",
      "64 loss: 105.19551486729299\n",
      "64 a: 1.1094611129588987\n",
      "65 loss: 105.19551486729299\n",
      "65 a: 1.1094611129588987\n",
      "66 loss: 105.19551486729299\n",
      "66 a: 1.1094611129588987\n",
      "67 loss: 105.19551486729299\n",
      "67 a: 1.1094611129588987\n",
      "68 loss: 105.19551486729299\n",
      "68 a: 1.1094611129588987\n",
      "69 loss: 105.19551486729299\n",
      "69 a: 1.1094611129588987\n",
      "70 loss: 105.19551486729299\n",
      "70 a: 1.1094611129588987\n",
      "71 loss: 105.19551486729299\n",
      "71 a: 1.1094611129588987\n",
      "72 loss: 105.19551486729299\n",
      "72 a: 1.1094611129588987\n",
      "73 loss: 105.19551486729299\n",
      "73 a: 1.1094611129588987\n",
      "74 loss: 105.19551486729299\n",
      "74 a: 1.1094611129588987\n",
      "75 loss: 105.19551486729299\n",
      "75 a: 1.1094611129588987\n",
      "76 loss: 105.19551486729299\n",
      "76 a: 1.1094611129588987\n",
      "77 loss: 105.19551486729299\n",
      "77 a: 1.1094611129588987\n",
      "78 loss: 105.19551486729299\n",
      "78 a: 1.1094611129588987\n",
      "79 loss: 105.19551486729299\n",
      "79 a: 1.1094611129588987\n",
      "80 loss: 105.19551486729299\n",
      "80 a: 1.1094611129588987\n",
      "81 loss: 105.19551486729299\n",
      "81 a: 1.1094611129588987\n",
      "82 loss: 105.19551486729299\n",
      "82 a: 1.1094611129588987\n",
      "83 loss: 105.19551486729299\n",
      "83 a: 1.1094611129588987\n",
      "84 loss: 105.19551486729299\n",
      "84 a: 1.1094611129588987\n",
      "85 loss: 105.19551486729299\n",
      "85 a: 1.1094611129588987\n",
      "86 loss: 105.19551486729299\n",
      "86 a: 1.1094611129588987\n",
      "87 loss: 105.19551486729299\n",
      "87 a: 1.1094611129588987\n",
      "88 loss: 105.19551486729299\n",
      "88 a: 1.1094611129588987\n",
      "89 loss: 105.19551486729299\n",
      "89 a: 1.1094611129588987\n",
      "90 loss: 105.19551486729299\n",
      "90 a: 1.1094611129588987\n",
      "91 loss: 105.19551486729299\n",
      "91 a: 1.1094611129588987\n",
      "92 loss: 105.19551486729299\n",
      "92 a: 1.1094611129588987\n",
      "93 loss: 105.19551486729299\n",
      "93 a: 1.1094611129588987\n",
      "94 loss: 105.19551486729299\n",
      "94 a: 1.1094611129588987\n",
      "95 loss: 105.19551486729299\n",
      "95 a: 1.1094611129588987\n",
      "96 loss: 105.19551486729299\n",
      "96 a: 1.1094611129588987\n",
      "97 loss: 105.19551486729299\n",
      "97 a: 1.1094611129588987\n",
      "98 loss: 105.19551486729299\n",
      "98 a: 1.1094611129588987\n",
      "99 loss: 105.19551486729299\n",
      "99 a: 1.1094611129588987\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for i in data:\n",
    "    x.append(i[0])\n",
    "    y.append(i[1])\n",
    "a=random.randint(1,100)\n",
    "epoch=100\n",
    "rate=0.0001\n",
    "for i in range(0,epoch):\n",
    "    print(str(i)+\" loss: \"+str(computeLoss(x,y,a)))\n",
    "    print(str(i)+\" a: \"+str(a))\n",
    "    for j in range(0,4):\n",
    "        a=a-rate*computeGrad(x[j],y[j],a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35., 50.],\n",
       "       [50., 70.],\n",
       "       [65., 75.],\n",
       "       [80., 80.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
